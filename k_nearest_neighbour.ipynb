{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "515738\n"
     ]
    }
   ],
   "source": [
    "data=pd.read_csv('Hotel_Reviews_2.csv') #read the csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How the model works\n",
    "This model is based on supervised learning: multiple data points with an associated target value (vector y) are observed. The model learns how to recognize new input (x) and predict the associated output (y) based on similar values (closest neighbours). K-nearest neighbors works well for this dataset. It is a simple algorithm to implement, easy to adapt to new training samples, and well-suited for this data size. The data is low-dimensional, which makes KNN perfect for this task. The low dimentional is making it possible to calculate the distance between the datapoints.\n",
    "\n",
    "### Data\n",
    "The data set \"Hotel_Reviews\" has over 500 000 data points which is a good foundation for modeltraining. It is a mix of values and text, so we have to preprocess this so the model can calculate our prediction. \n",
    "\n",
    "In this case, we chose to predict output y based on the 707 nearest neighbors. Choosing the number of neighbors k is important but challenging, as there is many correct answers.\n",
    "\n",
    "A small k results in low bias and high variance (the model adapts instantly to noise).\n",
    "A large k results in high bias and low variance (the model predicts values close to the mean).\n",
    "\n",
    "The goal is to find a value of k that is the perfect balance between bias and variance, and gives the best performance.\n",
    "Since this dataset contains over 500,000 data points, it is important to choose a k that is large enough to consider enough values when predicting y, but not so large that the model loses precision.\n",
    "\n",
    "Often, it is conveniant to set k ≈ √n, where n is the number of data points. This gives k ≈ 707 in our case. We have also experimented with other values of k to find the perfect value to be used.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the basic data cleaning process. This should be added in all the models\n",
    "# This cell is a bit slow to run, so it is intended to be run only once\n",
    "\n",
    "# This part drops the columns that are not needed in the model\n",
    "data.drop('Hotel_Address',axis=1,inplace=True)  # Drop the column 'Hotel_Address' due to lack of relevance\n",
    "data.drop('Review_Date',axis=1,inplace=True)    # Drop the column 'Review_Date' due to lack of complete data\n",
    "data.drop('Additional_Number_of_Scoring',axis=1,inplace=True)  # Drop the column 'Additional_Number_of_Scoring' due to not knowing what the numbers mean\n",
    "data.drop('lat',axis=1,inplace=True)    # Drop the column 'lat' due to lack of relevance\n",
    "data.drop('lng',axis=1,inplace=True)    # Drop the column 'lng' due to lack of relevance\n",
    "data.drop('Total_Number_of_Reviews',axis=1,inplace=True)    # Drop the column 'Total_Number_of_Reviews' due to the number seams to be incorrect\n",
    "\n",
    "\n",
    "# The next part of the code aims to split the 'Tags' column into multiple columns\n",
    "\n",
    "data['Tags'] = data['Tags'].apply(ast.literal_eval) # Convert the string to a list, This code is made by chatgpt\n",
    "\n",
    "# The following 3 lines of code is made by github copilot\n",
    "\n",
    "tags_expanded = data['Tags'].apply(pd.Series) # Expand the 'Tags' column into multiple columns\n",
    "\n",
    "tags_expanded.columns = [f'Tag_{i}' for i in range(tags_expanded.shape[1])] # Rename the columns for better readability\n",
    "\n",
    "data = pd.concat([data, tags_expanded], axis=1) # Concatenate the expanded tags with the original dataframe\n",
    "\n",
    "data.drop('Tags',axis=1,inplace=True)   # Drop the column 'Tags' due to the data being split into multiple columns\n",
    "\n",
    "# The next part of the code turns the 'days_since_review' and 'Tag_3' columns into integers\n",
    "data['days_since_review']=data['days_since_review'].str.extract('(\\d+)').astype(int) # Extract the number from the string. This code if made using chatgpt\n",
    "data['Tag_3'] = data['Tag_3'].str.extract('(\\d+)').astype(float) # Extract the number from the string and convert to float. For some reason it did not work as int\n",
    "\n",
    "# The next part of the code creates a new dataframe with hotel names and removes it from the dataframe data\n",
    "hotel_names = data['Hotel_Name'] # Create a new dataframe with the hotel names\n",
    "data.drop('Hotel_Name',axis=1,inplace=True) # Drop the column 'Hotel_Name' as it is not needed in the model\n",
    "\n",
    "\n",
    "\n",
    "data.fillna(0, inplace=True)  # Replace Nan-values with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Average_Score  Reviewer_Nationality  Review_Total_Negative_Word_Counts  \\\n",
      "0            7.7                   167                                397   \n",
      "1            7.7                    98                                  0   \n",
      "2            7.7                    14                                 42   \n",
      "3            7.7                   214                                210   \n",
      "4            7.7                   146                                140   \n",
      "\n",
      "   Review_Total_Positive_Word_Counts  \\\n",
      "0                                 11   \n",
      "1                                105   \n",
      "2                                 21   \n",
      "3                                 26   \n",
      "4                                  8   \n",
      "\n",
      "   Total_Number_of_Reviews_Reviewer_Has_Given  Reviewer_Score  \\\n",
      "0                                           7             2.9   \n",
      "1                                           7             7.5   \n",
      "2                                           9             7.1   \n",
      "3                                           1             3.8   \n",
      "4                                           3             6.7   \n",
      "\n",
      "   days_since_review  Tag_0  Tag_1  Tag_2  Tag_3  Tag_4  Tag_5  \n",
      "0                  0      5    132    685     28     15      1  \n",
      "1                  0      5    132    685     26     15      1  \n",
      "2                  3      5    442    685     23     14      1  \n",
      "3                  3      5    715    685     23     15      1  \n",
      "4                 10      5    132   1879     12     14      1  \n"
     ]
    }
   ],
   "source": [
    "knn_data = data.copy()\n",
    "\n",
    "knn_data.drop(['Negative_Review', 'Positive_Review'], axis=1, inplace=True) # In this model, these categories can not be used because the length of words that can not be converted to dummies.\n",
    "\n",
    "\n",
    "# Label encode non-numerical features. LabelEncoder is neccesary for the Kernel to not crash due to data overload. This will happend when too many unique values are created when converting categorical values to continous values.\n",
    "# Do this for all categories:\n",
    "label_encoded_reviwer_nationality = LabelEncoder()\n",
    "knn_data['Reviewer_Nationality'] = label_encoded_reviwer_nationality.fit_transform(knn_data['Reviewer_Nationality'])\n",
    "\n",
    "label_encoded_tag_0 = LabelEncoder()\n",
    "knn_data['Tag_0'] = label_encoded_tag_0.fit_transform(knn_data['Tag_0'].astype(str))\n",
    "\n",
    "label_encoded_tag_1 = LabelEncoder()\n",
    "knn_data['Tag_1'] = label_encoded_tag_1.fit_transform(knn_data['Tag_1'].astype(str))\n",
    "\n",
    "label_encoded_tag_2 = LabelEncoder()\n",
    "knn_data['Tag_2'] = label_encoded_tag_2.fit_transform(knn_data['Tag_2'].astype(str))\n",
    "\n",
    "label_encoded_tag_3 = LabelEncoder()\n",
    "knn_data['Tag_3'] = label_encoded_tag_3.fit_transform(knn_data['Tag_3'].astype(str))\n",
    "\n",
    "label_encoded_tag_4 = LabelEncoder()\n",
    "knn_data['Tag_4'] = label_encoded_tag_4.fit_transform(knn_data['Tag_4'].astype(str))\n",
    "\n",
    "label_encoded_tag_5 = LabelEncoder()\n",
    "knn_data['Tag_5'] = label_encoded_tag_5.fit_transform(knn_data['Tag_5'].astype(str))\n",
    "\n",
    "print(knn_data.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I chose to remove the categories \"Negative_Review\" and \"Positive Review\" because they are a string of text and therefore useless for this model. Removing these categories from the data set, makes the model running faster and easier to work with. \n",
    "\n",
    "Next, LabelEncoder is used to convert the categorical data to numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Modellens Nøyaktighet: 0.0384\n"
     ]
    }
   ],
   "source": [
    "features = knn_data.columns.difference(['Average_Score'])  # Returns all data except Avrage Score, because this might be higly correlated to what we want to predict\n",
    "scaler = MinMaxScaler()                                          \n",
    "knn_data[features] = scaler.fit_transform(knn_data[features])  # Scale the columns from 0-1\n",
    "\n",
    "\n",
    "X = knn_data.drop('Reviewer_Score', axis=1)     #Need to drop this column so the predited output is not the actual input\n",
    "y = knn_data['Reviewer_Score'] \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=68) # Split the data in to train/test-set\n",
    "\n",
    "knn = KNeighborsRegressor(n_neighbors=707)        # Use regression because the values are continuous\n",
    "knn.fit(X_train, y_train)                      \n",
    "\n",
    "y_pred = knn.predict(X_test)\n",
    "mse = mean_squared_error(y_test, y_pred)    #Distance from predicted value to actual value\n",
    "\n",
    "\n",
    "print(f'Accuracy: {mse:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose to remove the category \"Average_Score\" because this score might be highly correlated to the score we want to predict. If we not remove this category, we give the model all the input it needs to predict \"Reviewer_score\" and we allow the model to cheat. This gives us model that is too accurate, but not functional. We want the model to learn from all categories, and not based on an almost done result (score).\n",
    "\n",
    "Scaling is important so all the values are equally weighted. Since this model is based on distance to the neightbours, we would have a wrong result if not.\n",
    "\n",
    "The distance from predicted value to actual value is our mean squared error, and is used to measure accuracy of the model. Our model has a mse of 0.0384, which means that the model is suited for predicting data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='Reviewer_Score'>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "seaborn.boxplot(x=y_test-y_pred)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
